{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> HMS: <span style='color:#F1A424'>WaveNet</span><span style='color:#ABABAB'> [Train]</span></b> \n","\n","***\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:23:18.453670Z","iopub.status.busy":"2024-03-12T16:23:18.453363Z","iopub.status.idle":"2024-03-12T16:23:24.122813Z","shell.execute_reply":"2024-03-12T16:23:24.121696Z","shell.execute_reply.started":"2024-03-12T16:23:18.453644Z"},"trusted":true},"outputs":[],"source":["import gc\n","import math\n","import matplotlib.pyplot as plt\n","import multiprocessing\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","import time\n","import torch\n","import torch.nn as nn\n","\n","\n","from glob import glob\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","from typing import Dict, List\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('Using', torch.cuda.device_count(), 'GPU(s)')\n","!mkdir models"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:23:34.070321Z","iopub.status.busy":"2024-03-12T16:23:34.069535Z","iopub.status.idle":"2024-03-12T16:23:34.076992Z","shell.execute_reply":"2024-03-12T16:23:34.076132Z","shell.execute_reply.started":"2024-03-12T16:23:34.070283Z"},"trusted":true},"outputs":[],"source":["class config:\n","    AMP = True\n","    BATCH_SIZE_TRAIN = 32\n","    BATCH_SIZE_VALID = 32\n","    EPOCHS = 5\n","    FOLDS = 5\n","    GRADIENT_ACCUMULATION_STEPS = 1\n","    MAX_GRAD_NORM = 1e7\n","    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n","    PRINT_FREQ = 20\n","    SEED = 20\n","    TRAIN_FULL_DATA = False\n","    VISUALIZE = True\n","    WEIGHT_DECAY = 0.01\n","    \n","    \n","class paths:\n","    OUTPUT_DIR = \"/kaggle/working/\"\n","    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n","    TRAIN_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\""]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top) \n","\n","***\n","\n","Utility functions."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-03-12T16:23:37.248463Z","iopub.status.busy":"2024-03-12T16:23:37.248124Z","iopub.status.idle":"2024-03-12T16:23:37.273878Z","shell.execute_reply":"2024-03-12T16:23:37.272976Z","shell.execute_reply.started":"2024-03-12T16:23:37.248438Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s: float):\n","    \"Convert to minutes.\"\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since: float, percent: float):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def get_logger(filename=paths.OUTPUT_DIR):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","def eeg_from_parquet(parquet_path: str, display: bool = False) -> np.ndarray:\n","    \"\"\"\n","    This function reads a parquet file and extracts the middle 50 seconds of readings. Then it fills NaN values\n","    with the mean value (ignoring NaNs).\n","    :param parquet_path: path to parquet file.\n","    :param display: whether to display EEG plots or not.\n","    :return data: np.array of shape  (time_steps, eeg_features) -> (10_000, 8)\n","    \"\"\"\n","    # === Extract middle 50 seconds ===\n","    eeg = pd.read_parquet(parquet_path, columns=eeg_features)\n","    rows = len(eeg)\n","    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n","    eeg = eeg.iloc[offset:offset+10_000] # middle 50 seconds, has the same amount of readings to left and right\n","    if display: \n","        plt.figure(figsize=(10,5))\n","        offset = 0\n","    # === Convert to numpy ===\n","    data = np.zeros((10_000, len(eeg_features))) # create placeholder of same shape with zeros\n","    for index, feature in enumerate(eeg_features):\n","        x = eeg[feature].values.astype('float32') # convert to float32\n","        mean = np.nanmean(x) # arithmetic mean along the specified axis, ignoring NaNs\n","        nan_percentage = np.isnan(x).mean() # percentage of NaN values in feature\n","        # === Fill nan values ===\n","        if nan_percentage < 1: # if some values are nan, but not all\n","            x = np.nan_to_num(x, nan=mean)\n","        else: # if all values are nan\n","            x[:] = 0\n","        data[:, index] = x\n","        if display: \n","            if index != 0:\n","                offset += x.max()\n","            plt.plot(range(10_000), x-offset, label=feature)\n","            offset -= x.min()\n","    if display:\n","        plt.legend()\n","        name = parquet_path.split('/')[-1].split('.')[0]\n","        plt.yticks([])\n","        plt.title(f'EEG {name}',size=16)\n","        plt.show()    \n","    return data\n","\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed) \n","    \n","    \n","def sep():\n","    print(\"-\"*100)\n","\n","    \n","target_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n","label_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\n","num_to_label = {v: k for k, v in label_to_num.items()}\n","LOGGER = get_logger()\n","seed_everything(config.SEED)"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [↑](#top) \n","\n","***\n","\n","Load the competition's data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:23:39.557048Z","iopub.status.busy":"2024-03-12T16:23:39.556712Z","iopub.status.idle":"2024-03-12T16:23:39.827657Z","shell.execute_reply":"2024-03-12T16:23:39.826695Z","shell.execute_reply.started":"2024-03-12T16:23:39.557023Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(paths.TRAIN_CSV)\n","label_cols = train_df.columns[-6:]\n","print(f\"Train cataframe shape is: {train_df.shape}\")\n","print(f\"Labels: {list(label_cols)}\")\n","train_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["### <b><span style='color:#F1A424'>Read one EEG parquet</span></b>\n","\n","All of the EEG data (for both train and test) was collected at a frequency of 200 samples per second,\n","\n","Each EEG parquet results in a dataframe with `seconds` rows and 20 columns.\n","\n","- EEG features are: `['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']`\n","- We will use these features: `['Fp1','T3','C3','O1','Fp2','C4','T4','O2']`\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:23:42.692059Z","iopub.status.busy":"2024-03-12T16:23:42.691708Z","iopub.status.idle":"2024-03-12T16:23:42.951622Z","shell.execute_reply":"2024-03-12T16:23:42.950572Z","shell.execute_reply.started":"2024-03-12T16:23:42.692031Z"},"trusted":true},"outputs":[],"source":["eeg_df = pd.read_parquet(paths.TRAIN_EEGS + \"100261680.parquet\")\n","eeg_features = eeg_df.columns\n","print(f'There are {len(eeg_features)} raw eeg features')\n","print(list(eeg_features))\n","eeg_features = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n","feature_to_index = {x:y for x,y in zip(eeg_features, range(len(eeg_features)))}"]},{"cell_type":"markdown","metadata":{},"source":["### <b><span style='color:#F1A424'>Read all EEG parquets</span></b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T01:27:32.223792Z","iopub.status.busy":"2024-03-12T01:27:32.223420Z","iopub.status.idle":"2024-03-12T01:29:15.902355Z","shell.execute_reply":"2024-03-12T01:29:15.901301Z","shell.execute_reply.started":"2024-03-12T01:27:32.223760Z"},"trusted":true},"outputs":[],"source":["# %%time\n","\n","# CREATE_EEGS = False\n","# all_eegs = {}\n","# visualize = 1\n","# eeg_paths = glob(paths.TRAIN_EEGS + \"*.parquet\")\n","# eeg_ids = train_df.eeg_id.unique()\n","\n","# for i, eeg_id in tqdm(enumerate(eeg_ids)):  \n","#     # Save EEG to Python dictionary of numpy arrays\n","#     eeg_path = paths.TRAIN_EEGS + str(eeg_id) + \".parquet\"\n","#     data = eeg_from_parquet(eeg_path, display=i<visualize)              \n","#     all_eegs[eeg_id] = data\n","    \n","#     if i == visualize:\n","#         if CREATE_EEGS:\n","#             print(f'Processing {train_df.eeg_id.nunique()} eeg parquets... ',end='')\n","#         else:\n","#             print(f'Reading {len(eeg_ids)} eeg NumPys from disk.')\n","#             break\n","            \n","# if CREATE_EEGS: \n","#     np.save('eegs', all_eegs)\n","# else:\n","# #     all_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()\n","#     all_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:27:50.380331Z","iopub.status.busy":"2024-03-12T16:27:50.379427Z","iopub.status.idle":"2024-03-12T16:29:20.428964Z","shell.execute_reply":"2024-03-12T16:29:20.427941Z","shell.execute_reply.started":"2024-03-12T16:27:50.380297Z"},"trusted":true},"outputs":[],"source":["### read in each npy file\n","FILT_EEG_PATH = '/kaggle/input/all-filt-eegs/all_filt_eegs/'\n","all_eegs = dict() # this will hold all the filtered eegs\n","for f in os.listdir(FILT_EEG_PATH):\n","    this_dict = np.load(FILT_EEG_PATH+f,allow_pickle=True).item()\n","    all_eegs.update(this_dict)\n","\n","print(len(all_eegs.keys()))"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Data pre-processing</b><a class='anchor' id='preprocessing'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:30:00.766258Z","iopub.status.busy":"2024-03-12T16:30:00.765565Z","iopub.status.idle":"2024-03-12T16:30:00.773421Z","shell.execute_reply":"2024-03-12T16:30:00.772522Z","shell.execute_reply.started":"2024-03-12T16:30:00.766221Z"},"trusted":true},"outputs":[],"source":["eeg_ids = train_df.eeg_id.unique()\n","len(eeg_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:30:05.513880Z","iopub.status.busy":"2024-03-12T16:30:05.513160Z","iopub.status.idle":"2024-03-12T16:30:05.732047Z","shell.execute_reply":"2024-03-12T16:30:05.731214Z","shell.execute_reply.started":"2024-03-12T16:30:05.513846Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(paths.TRAIN_CSV)\n","label_cols = df.columns[-6:]\n","\n","train_df = df.groupby('eeg_id')[['patient_id']].agg('first')\n","aux = df.groupby('eeg_id')[label_cols].agg('sum') \n","\n","for label in label_cols:\n","    train_df[label] = aux[label].values\n","    \n","y_data = train_df[label_cols].values\n","y_data = y_data / y_data.sum(axis=1,keepdims=True)\n","train_df[label_cols] = y_data\n","\n","aux = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n","train_df['target'] = aux\n","\n","train_df = train_df.reset_index()\n","train_df = train_df.loc[train_df.eeg_id.isin(eeg_ids)]\n","print(f\"Train dataframe with unique eeg_id has shape: {train_df.shape}\")\n","train_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Validation</b><a class='anchor' id='validation'></a> [↑](#top) \n","\n","***\n","\n","We train using `GroupKFold` on `patient_id`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:30:09.883440Z","iopub.status.busy":"2024-03-12T16:30:09.882914Z","iopub.status.idle":"2024-03-12T16:30:10.395701Z","shell.execute_reply":"2024-03-12T16:30:10.394754Z","shell.execute_reply.started":"2024-03-12T16:30:09.883405Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import KFold, GroupKFold\n","\n","\n","gkf = GroupKFold(n_splits=config.FOLDS)\n","for fold, (train_index, valid_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n","    train_df.loc[valid_index, \"fold\"] = int(fold)\n","    \n","display(train_df.groupby('fold').size()), sep()\n","display(train_df.head())"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Butter Low-Pass Filter</b><a class='anchor' id='filter'></a> [↑](#top) \n","\n","***\n","\n","- [scipy.signal.butter()][1]\n","- [scipy.signal.lfilter()][2]\n","\n","[1]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html#scipy.signal.butter\n","[2]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html#scipy.signal.lfilter"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T15:44:35.425965Z","iopub.status.busy":"2024-02-16T15:44:35.42562Z","iopub.status.idle":"2024-02-16T15:44:35.48773Z","shell.execute_reply":"2024-02-16T15:44:35.487001Z","shell.execute_reply.started":"2024-02-16T15:44:35.425932Z"},"trusted":true},"outputs":[],"source":["# from scipy.signal import butter, lfilter\n","\n","# def butter_lowpass_filter(data, cutoff_freq: int = 20, sampling_rate: int = 200, order: int = 4):\n","#     nyquist = 0.5 * sampling_rate\n","#     normal_cutoff = cutoff_freq / nyquist\n","#     b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","#     filtered_data = lfilter(b, a, data, axis=0)\n","#     return filtered_data"]},{"cell_type":"markdown","metadata":{},"source":["## <b><span style='color:#F1A424'>Visualize</span></b>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-16T15:44:35.489059Z","iopub.status.busy":"2024-02-16T15:44:35.4888Z","iopub.status.idle":"2024-02-16T15:44:36.048322Z","shell.execute_reply":"2024-02-16T15:44:36.047381Z","shell.execute_reply.started":"2024-02-16T15:44:35.489036Z"},"trusted":true},"outputs":[],"source":["# frequencies = [1,2,4,8,16][::-1] # frequencies in Hz\n","# x = [all_eegs[eeg_ids[0]][:,0]] # select one EEG feature\n","\n","# for frequency in frequencies:\n","#     x.append(butter_lowpass_filter(x[0], cutoff_freq=frequency))\n","\n","# plt.figure(figsize=(12,8))\n","# plt.plot(range(10_000), x[0], label='without filter')\n","# for k in range(1,len(x)):\n","#     plt.plot(range(10_000),x[k]-k*(x[0].max()-x[0].min()), label=f'with filter {frequencies[k-1]}Hz')\n","\n","# plt.legend()\n","# plt.yticks([])\n","# plt.title('Butter Low-Pass Filter Examples',size=18)\n","# plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Our own pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:52:54.972457Z","iopub.status.busy":"2024-03-12T16:52:54.971517Z","iopub.status.idle":"2024-03-12T16:54:24.075267Z","shell.execute_reply":"2024-03-12T16:54:24.074376Z","shell.execute_reply.started":"2024-03-12T16:52:54.972420Z"},"trusted":true},"outputs":[],"source":["orig_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Dataset</b><a class='anchor' id='dataset'></a> [↑](#top) \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:57:57.427625Z","iopub.status.busy":"2024-03-12T16:57:57.427227Z","iopub.status.idle":"2024-03-12T16:57:57.443092Z","shell.execute_reply":"2024-03-12T16:57:57.442070Z","shell.execute_reply.started":"2024-03-12T16:57:57.427595Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(\n","        self, df: pd.DataFrame, config, mode: str = 'train',\n","        eegs: Dict[int, np.ndarray] = all_eegs, downsample: int = 5\n","    ): \n","        self.df = df\n","        self.config = config\n","        self.batch_size = self.config.BATCH_SIZE_TRAIN\n","        self.mode = mode\n","        self.eegs = eegs\n","        self.downsample = downsample\n","        \n","    def __len__(self):\n","        \"\"\"\n","        Length of dataset.\n","        \"\"\"\n","        return len(self.df)\n","        \n","    def __getitem__(self, index):\n","        \"\"\"\n","        Get one item.\n","        \"\"\"\n","        X, y = self.__data_generation(index)\n","        X = X[::self.downsample,:]\n","        output = {\n","            \"X\": torch.tensor(X, dtype=torch.float32),\n","            \"y\": torch.tensor(y, dtype=torch.float32)\n","        }\n","        return output\n","                        \n","    def __data_generation(self, index):\n","        row = self.df.iloc[index]\n","        X = np.zeros((10_000, 8), dtype='float32')\n","        y = np.zeros(6, dtype='float32')\n","        data = self.eegs[row.eeg_id]\n","        \n","        # === Feature engineering ===\n","        X[:,0] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['T3']]\n","        X[:,1] = data[:,feature_to_index['T3']] - data[:,feature_to_index['O1']]\n","\n","        X[:,2] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['C3']]\n","        X[:,3] = data[:,feature_to_index['C3']] - data[:,feature_to_index['O1']]\n","\n","        X[:,4] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['C4']]\n","        X[:,5] = data[:,feature_to_index['C4']] - data[:,feature_to_index['O2']]\n","\n","        X[:,6] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['T4']]\n","        X[:,7] = data[:,feature_to_index['T4']] - data[:,feature_to_index['O2']]\n","\n","        # === Standarize ===\n","        X = np.clip(X,-1024, 1024)\n","        X = np.nan_to_num(X, nan=0) / 32.0\n","\n","#         # === Butter Low-pass Filter ===\n","#         X = butter_lowpass_filter(X)\n","        \n","        if self.mode != 'test':\n","            y = row[label_cols].values.astype(np.float32)\n","            \n","        return X, y"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> DataLoader</b><a class='anchor' id='dataloader'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:57:58.027937Z","iopub.status.busy":"2024-03-12T16:57:58.027551Z","iopub.status.idle":"2024-03-12T16:57:58.042113Z","shell.execute_reply":"2024-03-12T16:57:58.041080Z","shell.execute_reply.started":"2024-03-12T16:57:58.027905Z"},"trusted":true},"outputs":[],"source":["train_dataset = CustomDataset(train_df, config, mode=\"train\")\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=config.BATCH_SIZE_TRAIN,\n","    shuffle=False,\n","    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n",")\n","output = train_dataset[0]\n","X, y = output[\"X\"], output[\"y\"]\n","print(f\"X shape: {X.shape}\")\n","print(f\"y shape: {y.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["### <b><span style='color:#F1A424'> Visualize DataLoader</span></b>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:57:58.515818Z","iopub.status.busy":"2024-03-12T16:57:58.515158Z","iopub.status.idle":"2024-03-12T16:58:01.408139Z","shell.execute_reply":"2024-03-12T16:58:01.407093Z","shell.execute_reply.started":"2024-03-12T16:57:58.515784Z"},"trusted":true},"outputs":[],"source":["if config.VISUALIZE:\n","    for batch in train_loader:\n","        X = batch.pop(\"X\")\n","        y = batch.pop(\"y\")\n","        for item in range(4):\n","            plt.figure(figsize=(20,4))\n","            offset = 0\n","            for col in range(X.shape[-1]):\n","                if col != 0:\n","                    offset -= X[item,:,col].min()\n","                plt.plot(range(2_000), X[item,:,col]+offset,label=f'feature {col+1}')\n","                offset += X[item,:,col].max()\n","            tt = f'{y[col][0]:0.1f}'\n","            for t in y[col][1:]:\n","                tt += f', {t:0.1f}'\n","            plt.title(f'EEG_Id = {eeg_ids[item]}\\nTarget = {tt}',size=14)\n","            plt.legend()\n","            plt.show()\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [↑](#top) \n","\n","***\n","\n","<center><img width = 800 src=\"https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Jan-2024/wave-model.png\"></center>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:58:01.410028Z","iopub.status.busy":"2024-03-12T16:58:01.409737Z","iopub.status.idle":"2024-03-12T16:58:01.456729Z","shell.execute_reply":"2024-03-12T16:58:01.455834Z","shell.execute_reply.started":"2024-03-12T16:58:01.410002Z"},"trusted":true},"outputs":[],"source":["class Wave_Block(nn.Module):\n","    def __init__(self, in_channels: int, out_channels: int, dilation_rates: int, kernel_size: int = 3):\n","        \"\"\"\n","        WaveNet building block.\n","        :param in_channels: number of input channels.\n","        :param out_channels: number of output channels.\n","        :param dilation_rates: how many levels of dilations are used.\n","        :param kernel_size: size of the convolving kernel.\n","        \"\"\"\n","        super(Wave_Block, self).__init__()\n","        self.num_rates = dilation_rates\n","        self.convs = nn.ModuleList()\n","        self.filter_convs = nn.ModuleList()\n","        self.gate_convs = nn.ModuleList()\n","        self.convs.append(nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=True))\n","        \n","        dilation_rates = [2 ** i for i in range(dilation_rates)]\n","        for dilation_rate in dilation_rates:\n","            self.filter_convs.append(\n","                nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size,\n","                          padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate))\n","            self.gate_convs.append(\n","                nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size,\n","                          padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate))\n","            self.convs.append(nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=True))\n","        \n","        for i in range(len(self.convs)):\n","            nn.init.xavier_uniform_(self.convs[i].weight, gain=nn.init.calculate_gain('relu'))\n","            nn.init.zeros_(self.convs[i].bias)\n","\n","        for i in range(len(self.filter_convs)):\n","            nn.init.xavier_uniform_(self.filter_convs[i].weight, gain=nn.init.calculate_gain('relu'))\n","            nn.init.zeros_(self.filter_convs[i].bias)\n","\n","        for i in range(len(self.gate_convs)):\n","            nn.init.xavier_uniform_(self.gate_convs[i].weight, gain=nn.init.calculate_gain('relu'))\n","            nn.init.zeros_(self.gate_convs[i].bias)\n","\n","    def forward(self, x):\n","        x = self.convs[0](x)\n","        res = x\n","        for i in range(self.num_rates):\n","            tanh_out = torch.tanh(self.filter_convs[i](x))\n","            sigmoid_out = torch.sigmoid(self.gate_convs[i](x))\n","            x = tanh_out * sigmoid_out\n","            x = self.convs[i + 1](x) \n","            res = res + x\n","        return res\n","    \n","class WaveNet(nn.Module):\n","    def __init__(self, input_channels: int = 1, kernel_size: int = 3):\n","        super(WaveNet, self).__init__()\n","        self.model = nn.Sequential(\n","                Wave_Block(input_channels, 8, 12, kernel_size),\n","                Wave_Block(8, 16, 8, kernel_size),\n","                Wave_Block(16, 32, 4, kernel_size),\n","                Wave_Block(32, 64, 1, kernel_size) \n","        )\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = x.permute(0, 2, 1) \n","        output = self.model(x)\n","        return output\n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super(CustomModel, self).__init__()\n","        self.model = WaveNet()\n","        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n","        self.dropout = 0.0\n","        self.head = nn.Sequential(\n","            nn.Linear(256, 64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.Dropout(self.dropout),\n","            nn.Linear(64, 6)\n","        )\n","        \n","    def forward(self, x: torch.Tensor):\n","        \"\"\"\n","        Forwward pass.\n","        \"\"\"\n","        x1 = self.model(x[:, :, 0:1])\n","        x1 = self.global_avg_pooling(x1)\n","        x1 = x1.squeeze()\n","        x2 = self.model(x[:, :, 1:2])\n","        x2 = self.global_avg_pooling(x2)\n","        x2 = x2.squeeze()\n","        z1 = torch.mean(torch.stack([x1, x2]), dim=0)\n","\n","        x1 = self.model(x[:, :, 2:3])\n","        x1 = self.global_avg_pooling(x1)\n","        x1 = x1.squeeze()\n","        x2 = self.model(x[:, :, 3:4])\n","        x2 = self.global_avg_pooling(x2)\n","        x2 = x2.squeeze()\n","        z2 = torch.mean(torch.stack([x1, x2]), dim=0)\n","        \n","        x1 = self.model(x[:, :, 4:5])\n","        x1 = self.global_avg_pooling(x1)\n","        x1 = x1.squeeze()\n","        x2 = self.model(x[:, :, 5:6])\n","        x2 = self.global_avg_pooling(x2)\n","        x2 = x2.squeeze()\n","        z3 = torch.mean(torch.stack([x1, x2]), dim=0)\n","        \n","        x1 = self.model(x[:, :, 6:7])\n","        x1 = self.global_avg_pooling(x1)\n","        x1 = x1.squeeze()\n","        x2 = self.model(x[:, :, 7:8])\n","        x2 = self.global_avg_pooling(x2)\n","        x2 = x2.squeeze()\n","        z4 = torch.mean(torch.stack([x1, x2]), dim=0)\n","        \n","        y = torch.cat([z1, z2, z3, z4], dim=1)\n","        y = self.head(y)\n","        \n","        return y\n","\n","model = CustomModel()\n","total_params = sum(p.numel() for p in model.parameters())\n","print(f\"Total number of parameters: {total_params}\")"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Scheduler</b><a class='anchor' id='scheduler'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:58:01.459881Z","iopub.status.busy":"2024-03-12T16:58:01.459593Z","iopub.status.idle":"2024-03-12T16:58:01.741998Z","shell.execute_reply":"2024-03-12T16:58:01.741092Z","shell.execute_reply.started":"2024-03-12T16:58:01.459856Z"},"trusted":true},"outputs":[],"source":["from torch.optim.lr_scheduler import OneCycleLR\n","\n","EPOCHS = config.EPOCHS\n","BATCHES = len(train_loader)\n","steps = []\n","lrs = []\n","optim_lrs = []\n","model = CustomModel()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n","scheduler = OneCycleLR(\n","    optimizer,\n","    max_lr=1e-3,\n","    epochs=config.EPOCHS,\n","    steps_per_epoch=len(train_loader),\n","    pct_start=0.1,\n","    anneal_strategy=\"cos\",\n","    final_div_factor=100,\n",")\n","for epoch in range(EPOCHS):\n","    for batch in range(BATCHES):\n","        scheduler.step()\n","        lrs.append(scheduler.get_last_lr()[0])\n","        steps.append(epoch * BATCHES + batch)\n","\n","max_lr = max(lrs)\n","min_lr = min(lrs)\n","print(f\"Maximum LR: {max_lr} | Minimum LR: {min_lr}\")\n","plt.figure()\n","plt.plot(steps, lrs, label='OneCycle')\n","plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"Learning Rate\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Loss Function</b><a class='anchor' id='loss'></a> [↑](#top) \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:58:01.744244Z","iopub.status.busy":"2024-03-12T16:58:01.743940Z","iopub.status.idle":"2024-03-12T16:58:01.757314Z","shell.execute_reply":"2024-03-12T16:58:01.756339Z","shell.execute_reply.started":"2024-03-12T16:58:01.744215Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","# === Reduction = \"mean\" ===\n","criterion = nn.KLDivLoss(reduction=\"mean\")\n","y_pred = F.log_softmax(torch.randn(6, 2, requires_grad=True), dim=1)\n","y_true = F.softmax(torch.rand(6, 2), dim=1)\n","print(f\"Predictions: {y_pred}\")\n","print(f\"Targets: {y_true}\")\n","output = criterion(y_pred, y_true)\n","print(f\"Output: {output}\")\n","\n","print(\"\\n\", \"=\"*100, \"\\n\")\n","\n","# === Reduction = \"batchmean\" ===\n","criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","y_pred = F.log_softmax(torch.randn(2, 6, requires_grad=True), dim=1)\n","y_true = F.softmax(torch.rand(2, 6), dim=1)\n","print(f\"Predictions: {y_pred}\")\n","print(f\"Targets: {y_true}\")\n","output = criterion(y_pred, y_true)\n","print(f\"Output: {output}\")"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:58:01.759009Z","iopub.status.busy":"2024-03-12T16:58:01.758734Z","iopub.status.idle":"2024-03-12T16:58:01.776795Z","shell.execute_reply":"2024-03-12T16:58:01.775958Z","shell.execute_reply.started":"2024-03-12T16:58:01.758985Z"},"trusted":true},"outputs":[],"source":["def train_epoch(train_loader, model, optimizer, epoch, scheduler, device):\n","    \"\"\"One epoch training pass.\"\"\"\n","    model.train()\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    scaler = torch.cuda.amp.GradScaler(enabled=config.AMP)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    \n","    # ========== ITERATE OVER TRAIN BATCHES ============\n","    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n","        for step, batch in enumerate(tqdm_train_loader):\n","            X = batch.pop(\"X\").to(device) # send inputs to `device`\n","            y = batch.pop(\"y\").to(device) # send labels to `device`\n","            batch_size = y.size(0)\n","            with torch.cuda.amp.autocast(enabled=config.AMP):\n","                y_preds = model(X)\n","                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n","            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n","            losses.update(loss.item(), batch_size)\n","            scaler.scale(loss).backward()\n","            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n","            \n","            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","                global_step += 1\n","                scheduler.step()\n","            end = time.time()\n","\n","            # ========== LOG INFO ==========\n","            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n","                print('Epoch: [{0}][{1}/{2}] '\n","                      'Elapsed {remain:s} '\n","                      'Loss: {loss.avg:.4f} '\n","                      'Grad: {grad_norm:.4f}  '\n","                      'LR: {lr:.8f}  '\n","                      .format(epoch+1, step, len(train_loader), \n","                              remain=timeSince(start, float(step+1)/len(train_loader)),\n","                              loss=losses,\n","                              grad_norm=grad_norm,\n","                              lr=scheduler.get_last_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_epoch(valid_loader, model, device):\n","    model.eval() \n","    softmax = nn.Softmax(dim=1)\n","    losses = AverageMeter()\n","    prediction_dict = {}\n","    preds = []\n","    start = end = time.time()\n","    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n","        for step, batch in enumerate(tqdm_valid_loader):\n","            X = batch.pop(\"X\").to(device) \n","            y = batch.pop(\"y\").to(device)\n","            batch_size = y.size(0)\n","            with torch.no_grad():\n","                y_preds = model(X)\n","                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n","            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n","                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n","            losses.update(loss.item(), batch_size)\n","            y_preds = softmax(y_preds)\n","            preds.append(y_preds.to('cpu').numpy()) \n","            end = time.time()\n","\n","            # ========== LOG INFO ==========\n","            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n","                print('EVAL: [{0}/{1}] '\n","                      'Elapsed {remain:s} '\n","                      'Loss: {loss.avg:.4f} '\n","                      .format(step, len(valid_loader),\n","                              remain=timeSince(start, float(step+1)/len(valid_loader)),\n","                              loss=losses))\n","                \n","    prediction_dict[\"predictions\"] = np.concatenate(preds)\n","    return losses.avg, prediction_dict"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:58:01.986096Z","iopub.status.busy":"2024-03-12T16:58:01.985338Z","iopub.status.idle":"2024-03-12T16:58:01.999249Z","shell.execute_reply":"2024-03-12T16:58:01.998217Z","shell.execute_reply.started":"2024-03-12T16:58:01.986060Z"},"trusted":true},"outputs":[],"source":["def train_loop(df, fold):\n","    \n","    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n","\n","    # ======== SPLIT ==========\n","    train_folds = df[df['fold'] != fold].reset_index(drop=True)\n","    valid_folds = df[df['fold'] == fold].reset_index(drop=True)\n","    \n","    # ======== DATASETS ==========\n","    train_dataset = CustomDataset(train_folds, config, mode=\"train\")\n","    valid_dataset = CustomDataset(valid_folds, config, mode=\"train\")\n","    \n","    # ======== DATALOADERS ==========\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=config.BATCH_SIZE_TRAIN,\n","                              shuffle=True,\n","                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=config.BATCH_SIZE_VALID,\n","                              shuffle=False,\n","                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n","    \n","    # ======== MODEL ==========\n","    model = CustomModel()\n","    model.to(device)\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n","    scheduler = OneCycleLR(\n","        optimizer,\n","        max_lr=1e-3,\n","        epochs=config.EPOCHS,\n","        steps_per_epoch=len(train_loader),\n","        pct_start=0.1,\n","        anneal_strategy=\"cos\",\n","        final_div_factor=100,\n","    )\n","\n","    # ======= LOSS ==========\n","    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n","    \n","    best_loss = np.inf\n","    # ====== ITERATE EPOCHS ========\n","    for epoch in range(config.EPOCHS):\n","        start_time = time.time()\n","\n","        # ======= TRAIN ==========\n","        avg_train_loss = train_epoch(train_loader, model, optimizer, epoch, scheduler, device)\n","\n","        # ======= EVALUATION ==========\n","        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, device)\n","        predictions = prediction_dict[\"predictions\"]\n","        \n","        # ======= SCORING ==========\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        \n","        if avg_val_loss < best_loss:\n","            best_loss = avg_val_loss\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                         f\"/kaggle/working/models/wavenet_fold_{fold}_best.pth\")\n","\n","    predictions = torch.load(f\"/kaggle/working/models/wavenet_fold_{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[target_preds] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"markdown","metadata":{},"source":["# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T16:58:02.810247Z","iopub.status.busy":"2024-03-12T16:58:02.809524Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["def get_result(oof_df):\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    labels = torch.tensor(oof_df[label_cols].values)\n","    preds = torch.tensor(oof_df[target_preds].values)\n","    preds = F.log_softmax(preds, dim=1)\n","    result = kl_loss(preds, labels)\n","    return result\n","\n","if not config.TRAIN_FULL_DATA:\n","    oof_df = pd.DataFrame()\n","    for fold in range(config.FOLDS):\n","        if fold in [0, 1, 2, 3, 4]:\n","            _oof_df = train_loop(train_df, fold)\n","            oof_df = pd.concat([oof_df, _oof_df])\n","            LOGGER.info(f\"========== Fold {fold} finished ==========\")\n","    oof_df = oof_df.reset_index(drop=True)\n","    oof_df.to_csv('/kaggle/working/models/oof_df.csv', index=False)\n","else:\n","    train_loop_full_data(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:45:16.622974Z","iopub.status.idle":"2024-02-16T15:45:16.623296Z","shell.execute_reply":"2024-02-16T15:45:16.623146Z","shell.execute_reply.started":"2024-02-16T15:45:16.623132Z"},"trusted":true},"outputs":[],"source":["! zip -r models.zip /kaggle/working/models"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-02-15T22:27:03.071564Z","iopub.status.busy":"2024-02-15T22:27:03.071166Z","iopub.status.idle":"2024-02-15T22:27:03.084649Z","shell.execute_reply":"2024-02-15T22:27:03.083623Z","shell.execute_reply.started":"2024-02-15T22:27:03.071534Z"}},"source":["# <b><span style='color:#F1A424'>|</span> Score</b><a class='anchor' id='score'></a> [↑](#top) \n","\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-16T15:45:16.624627Z","iopub.status.idle":"2024-02-16T15:45:16.624947Z","shell.execute_reply":"2024-02-16T15:45:16.624803Z","shell.execute_reply.started":"2024-02-16T15:45:16.624788Z"},"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append('/kaggle/input/kaggle-kl-div')\n","from kaggle_kl_div import score\n","\n","# === Pre-process OOF ===\n","label_cols = label_cols.tolist()\n","gt = train_df[[\"eeg_id\"] + label_cols]\n","gt.sort_values(by=\"eeg_id\", inplace=True)\n","gt.reset_index(inplace=True, drop=True)\n","\n","preds = oof_df[[\"eeg_id\"] + target_preds]\n","preds.columns = [\"eeg_id\"] + label_cols\n","preds.sort_values(by=\"eeg_id\", inplace=True)\n","preds.reset_index(inplace=True, drop=True)\n","\n","y_trues = gt[label_cols]\n","y_preds = preds[label_cols]\n","\n","oof = pd.DataFrame(y_preds.copy())\n","oof['id'] = np.arange(len(oof))\n","\n","true = pd.DataFrame(y_trues.copy())\n","true['id'] = np.arange(len(true))\n","\n","cv = score(solution=true, submission=oof, row_id_column_name='id')\n","print('CV Score with WaveNet Raw EEG =',cv)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4297749,"sourceId":7392733,"sourceType":"datasetVersion"},{"datasetId":4317718,"sourceId":7465251,"sourceType":"datasetVersion"},{"datasetId":4586319,"sourceId":7826547,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
